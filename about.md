---
layout: index
title: "About"
---


# About this page.

Awesome Multi-fidelity Fusion including the projects and work done by our team in the field of FidelityFusion

By leveraging the multi-fidelity data, the surrogate model can be trained with many low-fidelity data, which is cheap to generate, and a few high-fidelity data to predict the output of the high-fidelity simulation accurately.

FidelityFusion focus on tractable multi-fidelity fusion methods, which can be easily optimized and scaled to high-dimensional output with strong generalization and robustness.


```yaml
# pub.yaml
categories_publications:
  name: "All publications"
  categories:
    -
      heading: "Multi fidelity Fusion"
      file: Multi-fidelity_Fusion.bib
    -
      heading: "Bayesian optimization"
      file: Bayesian_optimization.bib
    -
      heading: "Uncertainty analysis"
      file: uncertainty_analysis.bib
    -
      heading: "Surrogate modeling"
      file: surrogate_modeling.bib
    
```

## The Team
FidelityFusion was developed and maintained by mainly by  [Wei. W. Xing](http://wxing.me) at [IceLab-X](https://icelab-x.github.io) and [Zen Xing](https://github.com/zen-xingle) at Rockchips.
A non-exhaustive but growing list needs to mention: [Yuxing Wang]() and [Guanjie Wang]() at BUAA.

## License
[LGPL-2.1 License](https://github.com/lululxvi/deepxde/blob/master/LICENSE)

# Citation
Please cite our paper if you find it helpful :) 

```
@inproceedings{
wang2022gar,
title={{GAR}}: Generalized Autoregression for Multi-Fidelity Fusion},
author={Yuxin Wang and Zheng Xing and WEI W. XING},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=aLNWp0pn1Ij}
}

```

